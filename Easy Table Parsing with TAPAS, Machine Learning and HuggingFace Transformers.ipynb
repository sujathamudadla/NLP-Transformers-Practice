{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27fbb818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.11\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b13f4a",
   "metadata": {},
   "source": [
    "To run the code, you will need to install the following things into an environment:\n",
    "\n",
    "HuggingFace Transformers: pip install transformers.\n",
    "A deep learning framework: either TensorFlow or PyTorch.\n",
    "Torch Scatter, which is a TAPAS dependency. The command is dependent on whether you are using it with PyTorch GPU or CPU. Replace 1.6.0 with your PyTorch version.\n",
    "For GPU: pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.6.0+${CUDA}.html\n",
    "For CPU: pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.6.0+cpu.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1af60662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.6.0+cpu.html\n",
      "Collecting torch-scatter\n",
      "  Downloading torch_scatter-2.0.9.tar.gz (21 kB)\n",
      "Building wheels for collected packages: torch-scatter\n",
      "  Building wheel for torch-scatter (setup.py): started\n",
      "  Building wheel for torch-scatter (setup.py): still running...\n",
      "  Building wheel for torch-scatter (setup.py): still running...\n",
      "  Building wheel for torch-scatter (setup.py): finished with status 'done'\n",
      "  Created wheel for torch-scatter: filename=torch_scatter-2.0.9-cp38-cp38-win_amd64.whl size=319061 sha256=dec34ee1d2e312132aeb93212979b95934f98954f32eb7903b6ac82966b10cc5\n",
      "  Stored in directory: c:\\users\\ramesh\\appdata\\local\\pip\\cache\\wheels\\7c\\51\\2a\\409339f45a48bf748a5db76dfa11373ea7c883ecf1932eee2f\n",
      "Successfully built torch-scatter\n",
      "Installing collected packages: torch-scatter\n",
      "Successfully installed torch-scatter-2.0.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.6.0+cpu.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17bc7ee",
   "metadata": {},
   "source": [
    "Model code\n",
    "Compared to Pipelines and other pretrained models, running TAPAS requires you to do a few more things. Below, you can find the code for the TAPAS based model as a whole. \n",
    "\n",
    "Imports: First of all, we’re importing the TapasTokenizer and TapasForQuestionAnswering imports from transformers – that is, HuggingFace Transformers. The tokenizer can be used for tokenization of which the result can be fed to the question answering model subsequently. Tapas requires a specific way of tokenization and input presenting, and these Tapas specific tokenizer and QA model have this built in. We also import pandas, which we’ll need later.\n",
    "Table and question definitions: next up is defining the table and the questions. As you can see, the table is defined as a Python dictionary. Our table has two columns – Cities and Inhabitants – and values (in millions of inhabitants) are provided for Paris, London and Lyon.\n",
    "Specifying some Python definitions:\n",
    "Loading the model and tokenizer: in load_model_and_tokenizer, we initialize the Tokenizer and QuestionAnswering model with a finetuned variant of TAPAS – more specifically, google/tapas-base-finetuned-wtq, or TAPAS finetuned on WikiTable Questions (WTQ).\n",
    "Preparing the inputs: our Python dictionary must first be converted into a DataFrame before it can be tokenized. We use pandas for this purpose, and create the dataframe from a dictionary. We can then feed it to the tokenizer together with the queries, and return the results.\n",
    "Generating the predictions: in generate_predictions, we feed the tokenized inputs to our TAPAS model. Our tokenizer can be used subsequently to find the cell coordinates and aggregation operators that were predicted – recall that TAPAS predicts relevant cells (the coordinates) and an operator that must be executed to answer the question (the aggregation operator).\n",
    "Postprocessing the predictions: in postprocess_predictions, we convert the predictions into a format that can be displayed on screen.\n",
    "Showing the answers: in show_answers, we then actually visualize these answers.\n",
    "Running TAPAS: run_tapas combines all other defs together in an end-to-end flow. This wasn’t directly added to __main__ because it’s best practice to keep as much functionality within Python definitions.\n",
    "Running the whole thing: so far, we have created a lot of definitions, but nothing is running yet. That’s why we check whether our Python is running with that if statement at the bottom, and if so, invoke run_tapas() – and therefore the whole model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23003d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5caba2e8aff4217aae7c014201a0571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/256k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8afe36ee796c4014a8a8977c9bd47837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/154 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245765f731194e78acccb7236fd70eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/490 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d15db67fa84a96b074dd8edfc874b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05621d6185ee4e3cab47267e15122120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/422M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which city has most inhabitants?\n",
      "Predicted answer: London, England\n",
      "What is the average number of inhabitants?\n",
      "Predicted answer: AVERAGE > 2.161, 8.982, 0.513\n",
      "How many French cities are in the list?\n",
      "Predicted answer: COUNT > Paris, France, Lyon, France\n",
      "How many inhabitants live in French cities?\n",
      "Predicted answer: SUM > 2.161, 0.513\n"
     ]
    }
   ],
   "source": [
    "from transformers import TapasTokenizer, TapasForQuestionAnswering\n",
    "import pandas as pd\n",
    "\n",
    "# Define the table\n",
    "data = {'Cities': [\"Paris, France\", \"London, England\", \"Lyon, France\"], 'Inhabitants': [\"2.161\", \"8.982\", \"0.513\"]}\n",
    "\n",
    "# Define the questions\n",
    "queries = [\"Which city has most inhabitants?\", \"What is the average number of inhabitants?\", \"How many French cities are in the list?\", \"How many inhabitants live in French cities?\"]\n",
    "\n",
    "def load_model_and_tokenizer():\n",
    "  \"\"\"\n",
    "    Load\n",
    "  \"\"\"\n",
    "  # Load pretrained tokenizer: TAPAS finetuned on WikiTable Questions\n",
    "  tokenizer = TapasTokenizer.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n",
    "\n",
    "  # Load pretrained model: TAPAS finetuned on WikiTable Questions\n",
    "  model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n",
    "\n",
    "  # Return tokenizer and model\n",
    "  return tokenizer, model\n",
    "\n",
    "\n",
    "def prepare_inputs(data, queries, tokenizer):\n",
    "  \"\"\"\n",
    "    Convert dictionary into data frame and tokenize inputs given queries.\n",
    "  \"\"\"\n",
    "  # Prepare inputs\n",
    "  table = pd.DataFrame.from_dict(data)\n",
    "  inputs = tokenizer(table=table, queries=queries, padding='max_length', return_tensors=\"pt\")\n",
    "  \n",
    "  # Return things\n",
    "  return table, inputs\n",
    "\n",
    "\n",
    "def generate_predictions(inputs, model, tokenizer):\n",
    "  \"\"\"\n",
    "    Generate predictions for some tokenized input.\n",
    "  \"\"\"\n",
    "  # Generate model results\n",
    "  outputs = model(**inputs)\n",
    "\n",
    "  # Convert logit outputs into predictions for table cells and aggregation operators\n",
    "  predicted_table_cell_coords, predicted_aggregation_operators = tokenizer.convert_logits_to_predictions(\n",
    "          inputs,\n",
    "          outputs.logits.detach(),\n",
    "          outputs.logits_aggregation.detach()\n",
    "  )\n",
    "  \n",
    "  # Return values\n",
    "  return predicted_table_cell_coords, predicted_aggregation_operators\n",
    "\n",
    "\n",
    "def postprocess_predictions(predicted_aggregation_operators, predicted_table_cell_coords, table):\n",
    "  \"\"\"\n",
    "    Compute the predicted operation and nicely structure the answers.\n",
    "  \"\"\"\n",
    "  # Process predicted aggregation operators\n",
    "  aggregation_operators = {0: \"NONE\", 1: \"SUM\", 2: \"AVERAGE\", 3:\"COUNT\"}\n",
    "  aggregation_predictions_string = [aggregation_operators[x] for x in predicted_aggregation_operators]\n",
    "\n",
    "  # Process predicted table cell coordinates\n",
    "  answers = []\n",
    "  for coordinates in predicted_table_cell_coords:\n",
    "    if len(coordinates) == 1:\n",
    "      # 1 cell\n",
    "      answers.append(table.iat[coordinates[0]])\n",
    "    else:\n",
    "      # > 1 cell\n",
    "      cell_values = []\n",
    "      for coordinate in coordinates:\n",
    "        cell_values.append(table.iat[coordinate])\n",
    "      answers.append(\", \".join(cell_values))\n",
    "      \n",
    "  # Return values\n",
    "  return aggregation_predictions_string, answers\n",
    "\n",
    "\n",
    "def show_answers(queries, answers, aggregation_predictions_string):\n",
    "  \"\"\"\n",
    "    Visualize the postprocessed answers.\n",
    "  \"\"\"\n",
    "  for query, answer, predicted_agg in zip(queries, answers, aggregation_predictions_string):\n",
    "    print(query)\n",
    "    if predicted_agg == \"NONE\":\n",
    "      print(\"Predicted answer: \" + answer)\n",
    "    else:\n",
    "      print(\"Predicted answer: \" + predicted_agg + \" > \" + answer)\n",
    "\n",
    "\n",
    "def run_tapas():\n",
    "  \"\"\"\n",
    "    Invoke the TAPAS model.\n",
    "  \"\"\"\n",
    "  tokenizer, model = load_model_and_tokenizer()\n",
    "  table, inputs = prepare_inputs(data, queries, tokenizer)\n",
    "  predicted_table_cell_coords, predicted_aggregation_operators = generate_predictions(inputs, model, tokenizer)\n",
    "  aggregation_predictions_string, answers = postprocess_predictions(predicted_aggregation_operators, predicted_table_cell_coords, table)\n",
    "  show_answers(queries, answers, aggregation_predictions_string)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  run_tapas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a4ba7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
